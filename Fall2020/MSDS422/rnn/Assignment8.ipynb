{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries needed for the analysis\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import random\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Recall is the number of relevant documents retrieved by a search\n",
    "    divided by\n",
    "    the total number of existing relevant documents;\n",
    "    \n",
    "    True & predicted positives divided by Total True positives\n",
    "                                (regardless of what was predicted);\n",
    "    \n",
    "    The True Positive Rate.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Precision is number of relevant documents retrieved by a search\n",
    "    divided by\n",
    "    the total number of documents retrieved by that search.\n",
    "    \n",
    "    True Positives / Predicted Positives\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed value for random number generators to obtain reproducible results\n",
    "RANDOM_SEED = 5\n",
    "from numpy.random import seed\n",
    "seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "dims = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training and test datasets\n",
    "train_tweets = pd.read_csv(\"/Users/kerry//Projects/grad_school_portfolio/Fall2020/MSDS422/rnn/data/train.csv\")\n",
    "test_tweets = pd.read_csv(\"/Users/kerry//Projects/grad_school_portfolio/Fall2020/MSDS422/rnn/data/test.csv\")\n",
    "#train_tweets= pd.read_csv('/Users/harini-mac/Desktop/Northwestern University/MSDS-422/Week8/project1/nlp-getting-started/train.csv')\n",
    "#test_tweets=pd.read_csv('/Users/harini-mac/Desktop/Northwestern University/MSDS-422/Week8/project1/nlp-getting-started/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>10863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#WorldNews Fallen powerlines on G:link tram: U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>10864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on the flip side I'm at Walmart and there is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7606</th>\n",
       "      <td>10866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suicide bomber kills 15 in Saudi security site...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7503 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7604  10863     NaN      NaN   \n",
       "7605  10864     NaN      NaN   \n",
       "7606  10866     NaN      NaN   \n",
       "7608  10869     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7604  #WorldNews Fallen powerlines on G:link tram: U...       1  \n",
       "7605  on the flip side I'm at Walmart and there is a...       1  \n",
       "7606  Suicide bomber kills 15 in Saudi security site...       1  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7503 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drops dups (retweets)\n",
    "train_tweets[train_tweets.duplicated(subset=\"text\", keep='first')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>938</td>\n",
       "      <td>blaze</td>\n",
       "      <td>Temecula, CA</td>\n",
       "      <td>Pendleton media office said only fire on base ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>940</td>\n",
       "      <td>blaze</td>\n",
       "      <td>Fresno, CA</td>\n",
       "      <td>Love living on my own. I can blaze inside my a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>945</td>\n",
       "      <td>blaze</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Property losses from California wildfire nearl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>946</td>\n",
       "      <td>blaze</td>\n",
       "      <td>Raleigh Durham, NC</td>\n",
       "      <td>#breaking Firefighters battling blaze at east ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>964</td>\n",
       "      <td>blaze</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>Property losses from #California wildfire near...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id keyword            location  \\\n",
       "647  938   blaze        Temecula, CA   \n",
       "649  940   blaze          Fresno, CA   \n",
       "653  945   blaze           Australia   \n",
       "654  946   blaze  Raleigh Durham, NC   \n",
       "669  964   blaze            Karachi    \n",
       "\n",
       "                                                  text  target  \n",
       "647  Pendleton media office said only fire on base ...       1  \n",
       "649  Love living on my own. I can blaze inside my a...       1  \n",
       "653  Property losses from California wildfire nearl...       1  \n",
       "654  #breaking Firefighters battling blaze at east ...       1  \n",
       "669  Property losses from #California wildfire near...       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drops ~ 5-10 records most of which I find misclassified\n",
    "train_tweets[(train_tweets.keyword==\"blaze\") & (train_tweets.target==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                      Non-Null Count  Dtype \n",
      "---  ------                                      --------------  ----- \n",
      " 0   Model_name                                  0 non-null      object\n",
      " 1   vocabulary size (factor1)                   0 non-null      object\n",
      " 2   pre-trained vector (factor2)                0 non-null      object\n",
      " 3   RNN structure (factor3)                     0 non-null      object\n",
      " 4   hyperparameter recurrent_dropout (factor4)  0 non-null      object\n",
      " 5   Processing Time                             0 non-null      object\n",
      " 6   Training Set Accuracy                       0 non-null      object\n",
      " 7   Validation Set Accuracy                     0 non-null      object\n",
      " 8   train f1                                    0 non-null      object\n",
      " 9   validation f1                               0 non-null      object\n",
      " 10  Test Set F1-score (Kaggle score)            0 non-null      object\n",
      "dtypes: object(11)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "#Create a dataframe to store the model accuracy and scores\n",
    "results_tbl = pd.DataFrame(columns=['Model_name','vocabulary size (factor1)', 'pre-trained vector (factor2)','RNN structure (factor3)','hyperparameter recurrent_dropout (factor4)','Processing Time','Training Set Accuracy','Validation Set Accuracy','train f1','validation f1','Test Set F1-score (Kaggle score)'])\n",
    "results_tbl.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'target count plot in the training data (0 - not a real disaster, 1 - a real disaster)')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count plot of the targets in training data \n",
    "sns.countplot(train_tweets['target'], palette=\"husl\")\n",
    "plt.title('target count plot in the training data (0 - not a real disaster, 1 - a real disaster)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any null values \n",
    "# the variable of interest in the data is text.\n",
    "train_tweets.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the length of the tweets in the training data\n",
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n",
    "disaster_tweets_len = train_tweets[train_tweets['target']==1]['text'].str.len()\n",
    "nondisaster_tweets_len = train_tweets[train_tweets['target']==0]['text'].str.len()\n",
    "ax1.hist(disaster_tweets_len, color=\"magenta\")\n",
    "ax1.set_title('char length disaster tweets - train')\n",
    "ax2.hist(nondisaster_tweets_len, color=\"purple\")\n",
    "ax2.set_title('char length non-disaster tweets - train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the word lengths of the tweets in the  training data\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "diaster_tweet_lengths=train_tweets[train_tweets['target']==1]['text'].str.split().map(lambda x: len(x))\n",
    "ax1.hist(diaster_tweet_lengths,color='blue')\n",
    "ax1.set_title('word length distribution of \\n disaster tweets in training data')\n",
    "nondisaster_tweet_lengths=train_tweets[train_tweets['target']==0]['text'].str.split().map(lambda x: len(x))\n",
    "ax2.hist(nondisaster_tweet_lengths,color='yellow')\n",
    "ax2.set_title('word length distribution of \\n non-disaster tweets in training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read function for the  GloVe (global vectors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading from the file to turn the words to word embedding vector\n",
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Glove file - glove.6B.200d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading from the file to learn the word embedding into the list word_to_vec_map\n",
    "#word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/Users/harini-mac/Desktop/Northwestern University/MSDS-422/Week8/project1/nlp-getting-started/embeddings/gloVe.6B/glove.6B.50d.txt')\n",
    "#word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/Users/kerry/Downloads/embeddings/gloVe.6B/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading from the file to learn the word embedding into the list word_to_vec_map\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/Users/kerry/Downloads/embeddings/gloVe.6B/glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanse the training and test data \n",
    "## Use the word_to_vec_map from glove.6B.50d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "#    rgx_fix_caps = \"(?<=[\\.!?]\\s)([A-Z])\" # fixes like Hello into hello???\n",
    "#    subst = r\"\\\\\"\n",
    "#    pre_sentence = re.sub(rgx_fix_caps, subst, text)\n",
    "    \n",
    "    rgx_rmv_punc = re.compile('([^\\s\\w]|_)+') # removes punctuation\n",
    "    sentence = rgx_rmv_punc.sub(\"\", text).lower()\n",
    "    \n",
    "    sentence = sentence.split(\" \")\n",
    "    \n",
    "    for word in list(sentence):\n",
    "        if word not in word_to_vec_map: # removes word if it's not in the 'dictionary' (txt file). case-sensitive.\n",
    "            sentence.remove(word)\n",
    "            \n",
    "    sentence = \" \".join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(train_tweets.loc[2,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (train_tweets.shape[0]):\n",
    "    train_tweets.at[i,'text']=clean(train_tweets.loc[i,'text'])\n",
    "    \n",
    "for i in range(test_tweets.shape[0]):\n",
    "    test_tweets.at[i,'text']=clean(test_tweets.loc[i,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_tweets['text']\n",
    "test_text = test_tweets['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the text in the training data\n",
    "# Pad the resultant sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57693333/processing-before-or-after-train-test-split\n",
    "# https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[178, 42, 214, 664, 6037, 6038, 1319]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"Forest fire near La Ronge Sask. Canada\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest fire near la ronge sask canada']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[178, 42, 214, 664, 6037, 6038, 1319]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens :  12256\n"
     ]
    }
   ],
   "source": [
    "word2index = tokenizer.word_index\n",
    "print(\"Number of unique tokens : \",len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = tokenizer.document_count\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get max training sequence length\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 31)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq = keras.preprocessing.sequence.pad_sequences(train_sequences,maxlen)\n",
    "X_train = padded_seq\n",
    "Y_train = train_tweets['target']\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embedding matrix for tokens in the training data - 200 Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word2index)+1, dims))\n",
    "\n",
    "embedding_vec=[]\n",
    "for word, i in word2index.items():\n",
    "    embedding_vec = word_to_vec_map.get(word)\n",
    "    if embedding_vec is not None:\n",
    "        embedding_matrix[i] = embedding_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.1549e-02  9.3459e-02  2.3738e-02 -9.0339e-02  5.6123e-02  3.2547e-01\n",
      " -3.9796e-01 -9.2139e-02  6.1181e-02 -1.8950e-01  1.3061e-01  1.4349e-01\n",
      "  1.1479e-02  3.8158e-01  5.4030e-01 -1.4088e-01  2.4315e-01  2.3036e-01\n",
      " -5.5339e-01  4.8154e-02  4.5662e-01  3.2338e+00  2.0199e-02  4.9019e-02\n",
      " -1.4132e-02  7.6017e-02 -1.1527e-01  2.0060e-01 -7.7657e-02  2.4328e-01\n",
      "  1.6368e-01 -3.4118e-01 -6.6070e-02  1.0152e-01  3.8232e-02 -1.7668e-01\n",
      " -8.8153e-01 -3.3895e-01 -3.5481e-02 -5.5095e-01 -1.6899e-02 -4.3982e-01\n",
      "  3.9004e-02  4.0447e-01 -2.5880e-01  6.4594e-01  2.6641e-01  2.8009e-01\n",
      " -2.4625e-02  6.3302e-01 -3.1700e-01  1.0271e-01  3.0886e-01  9.7792e-02\n",
      " -3.8227e-01  8.6552e-02  4.7075e-02  2.3511e-01 -3.2127e-01 -2.8538e-01\n",
      "  1.6670e-01 -4.9707e-03 -6.2714e-01 -2.4904e-01  2.9713e-01  1.4379e-01\n",
      " -1.2325e-01 -5.8178e-02 -1.0290e-03 -8.2126e-02  3.6935e-01 -5.8442e-04\n",
      "  3.4286e-01  2.8426e-01 -6.8599e-02  6.5747e-01 -2.9087e-02  1.6184e-01\n",
      "  7.3672e-02 -3.0343e-01  9.5733e-02 -5.2860e-01 -2.2898e-01  6.4079e-02\n",
      "  1.5218e-02  3.4921e-01 -4.3960e-01 -4.3983e-01  7.7515e-01 -8.7767e-01\n",
      " -8.7504e-02  3.9598e-01  6.2362e-01 -2.6211e-01 -3.0539e-01 -2.2964e-02\n",
      "  3.0567e-01  6.7660e-02  1.5383e-01 -1.1211e-01 -9.1540e-02  8.2562e-02\n",
      "  1.6897e-01 -3.2952e-02 -2.8775e-01 -2.2320e-01 -9.0426e-02  1.2407e+00\n",
      " -1.8244e-01 -7.5219e-03 -4.1388e-02 -1.1083e-02  7.8186e-02  3.8511e-01\n",
      "  2.3334e-01  1.4414e-01 -9.1070e-04 -2.6388e-01 -2.0481e-01  1.0099e-01\n",
      "  1.4076e-01  2.8834e-01 -4.5429e-02  3.7247e-01  1.3645e-01 -6.7457e-01\n",
      "  2.2786e-01  1.2599e-01  2.9091e-02  3.0428e-02 -1.3028e-01  1.9408e-01\n",
      "  4.9014e-01 -3.9121e-01 -7.5952e-02  7.4731e-02  1.8902e-01 -1.6922e-01\n",
      " -2.6019e-01 -3.9771e-02 -2.4153e-01  1.0875e-01  3.0434e-01  3.6009e-02\n",
      "  1.4264e+00  1.2759e-01 -7.3811e-02 -2.0418e-01  8.0016e-03  1.5381e-01\n",
      "  2.0223e-01  2.8274e-01  9.6206e-02 -3.3634e-01  5.0983e-01  3.2625e-01\n",
      " -2.6535e-01  3.7400e-01 -3.0388e-01 -4.0033e-01 -4.2910e-02 -6.7897e-02\n",
      " -2.9332e-01  1.0978e-01 -4.5365e-02  2.3222e-01 -3.1134e-01 -2.8983e-01\n",
      " -6.6687e-01  5.3097e-01  1.9461e-01  3.6670e-01  2.6185e-01 -6.5187e-01\n",
      "  1.0266e-01  1.1363e-01 -1.2953e-01 -6.8246e-01 -1.8751e-01  1.4760e-01\n",
      "  1.0765e+00 -2.2908e-01 -9.3435e-03 -2.0651e-01 -3.5225e-01 -2.6720e-01\n",
      " -3.4307e-03  2.5906e-01  2.1759e-01  6.6158e-01  1.2180e-01  1.9957e-01\n",
      " -2.0303e-01  3.4474e-01 -2.4328e-01  1.3139e-01 -8.8767e-03  3.3617e-01\n",
      "  3.0591e-02  2.5577e-01]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12257, 200)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RNN 1\n",
    "# vocabulary size (factor 1): 400K\n",
    "# pre-trained vector (factor 2): GloVe.6B.50d\n",
    "# rnn structure (factor 3): LSTM layer based structure\n",
    "# recurrent dropout (factor 4): 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.Sequential([\n",
    "    keras.layers.Embedding(len(word2index)+1,\n",
    "                           dims,\n",
    "                           weights=[embedding_matrix],\n",
    "                           input_length=maxlen,\n",
    "                           trainable=True),\n",
    "    keras.layers.LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.1 , dropout = 0.1),\n",
    "    keras.layers.LSTM(units=64 , recurrent_dropout = 0.1 , dropout = 0.1),\n",
    "    keras.layers.Dense(32, activation='tanh'),\n",
    "    keras.layers.Dense(4, activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 31, 200)           2451400   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 31, 128)           168448    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 2,671,468\n",
      "Trainable params: 2,671,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(learning_rate=1e-5)\n",
    "model1.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy', f1_m],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "167/167 [==============================] - 32s 191ms/step - loss: 1.4010 - accuracy: 0.2034 - f1_m: 8.5543e-04 - val_loss: 0.9089 - val_accuracy: 0.1896 - val_f1_m: 0.0019\n",
      "Epoch 2/30\n",
      "167/167 [==============================] - 33s 195ms/step - loss: 0.8484 - accuracy: 0.1610 - f1_m: 0.0426 - val_loss: 0.7652 - val_accuracy: 0.1642 - val_f1_m: 0.1022\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 32s 192ms/step - loss: 0.7568 - accuracy: 0.1409 - f1_m: 0.2205 - val_loss: 0.7147 - val_accuracy: 0.1458 - val_f1_m: 0.3519\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 32s 193ms/step - loss: 0.7203 - accuracy: 0.1368 - f1_m: 0.4633 - val_loss: 0.6910 - val_accuracy: 0.1554 - val_f1_m: 0.5181\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 35s 211ms/step - loss: 0.6949 - accuracy: 0.1509 - f1_m: 0.6195 - val_loss: 0.6712 - val_accuracy: 0.1664 - val_f1_m: 0.6275\n",
      "Epoch 6/30\n",
      "133/167 [======================>.......] - ETA: 6s - loss: 0.6769 - accuracy: 0.1572 - f1_m: 0.7170"
     ]
    }
   ],
   "source": [
    "# Fit the model; obtain the model fit time\n",
    "start=datetime.now()\n",
    "history1 = model1.fit(X_train,Y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_split=0.3\n",
    ")\n",
    "end=datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Train Accuracy: ')\n",
    "best_model_train_accuracy = np.round(history1.history['accuracy'][np.argmin(history1.history['loss'])],4)\n",
    "best_model_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Validation Accuracy: ')\n",
    "best_model_val_accuracy = np.round(history1.history['val_accuracy'][np.argmin(history1.history['val_loss'])],4)\n",
    "best_model_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = max(np.round(history1.history['f1_m'],4))\n",
    "print ('Best Train f1: {}'.format(best_model_train_f1))\n",
    "\n",
    "best_model_val_f1 = max(np.round(history1.history['val_f1_m'],4))\n",
    "print ('Best val f1: {}'.format(best_model_val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "pd.DataFrame(history1.history).plot(figsize=(10, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.title('Learning curve -  factor1: 400K, factor2: GloVe.6B.50d, factor3: LSTM, factor4: 0.1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_text)\n",
    "padded_seq = keras.preprocessing.sequence.pad_sequences(test_sequences,maxlen)\n",
    "X_test = padded_seq\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the prediction on the test data\n",
    "# 1 - disaster tweet , 0 - non-disaster tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1 = model1.predict_classes(X_test)\n",
    "predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv\n",
    "submission_df = pd.DataFrame({'id':test_tweets['id'],'target':np.squeeze(predict1)})\n",
    "submission_df.to_csv('submission_rnn_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the accuracy and kaggle score for this model \n",
    "results_tbl = results_tbl.append({'Model_name':'RNN #1', \n",
    "                                   'vocabulary size (factor1)':'400K',\n",
    "                                   'pre-trained vector (factor2)':'GloVe.6B.50d',\n",
    "                                   'RNN structure (factor3)':'LSTM layer based',\n",
    "                                   'hyperparameter recurrent_dropout (factor4)': '0.1',\n",
    "                                   'Processing Time':(end-start),\n",
    "                                   'Training Set Accuracy':best_model_train_accuracy,\n",
    "                                   'Validation Set Accuracy':best_model_val_accuracy,\n",
    "                                   'train f1':best_model_train_f1,\n",
    "                                   'validation f1':best_model_val_f1,\n",
    "                                   'Test Set F1-score (Kaggle score)': '0.78087'\n",
    "                                   },ignore_index=True)\n",
    "results_tbl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RNN 2\n",
    "# vocabulary size (factor 1): 400K\n",
    "# pre-trained vector (factor 2): GloVe.6B.200d\n",
    "# rnn structure (factor 3): LSTM layer based structure\n",
    "# recurrent dropout (factor 4): 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Embedding(len(word2index)+1,50,weights=[embedding_matrix],input_length=maxlen,trainable=False),\n",
    "    keras.layers.LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.3 , dropout = 0.3),\n",
    "    keras.layers.LSTM(units=64 , recurrent_dropout = 0.3 , dropout = 0.3),\n",
    "    keras.layers.Dense(32, activation='tanh'),\n",
    "    keras.layers.Dense(1,activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(learning_rate=1e-5)\n",
    "model2.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy', f1_m],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model; obtain the model fit time\n",
    "start=datetime.now()\n",
    "history2 = model2.fit(X_train,Y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=40,\n",
    "                    validation_split=0.3\n",
    ")\n",
    "end=datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Train Accuracy: ')\n",
    "best_model_train_accuracy = np.round(history2.history['accuracy'][np.argmin(history2.history['loss'])],4)\n",
    "best_model_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Validation Accuracy: ')\n",
    "best_model_val_accuracy = np.round(history2.history['val_accuracy'][np.argmin(history2.history['val_loss'])],4)\n",
    "best_model_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = max(np.round(history2.history['f1_m'],4))\n",
    "print ('Best Train f1: {}'.format(best_model_train_f1))\n",
    "\n",
    "best_model_val_f1 = max(np.round(history2.history['val_f1_m'],4))\n",
    "print ('Best val f1: {}'.format(best_model_val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "pd.DataFrame(history2.history).plot(figsize=(10, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.title('Learning curve -  factor1: 400K, factor2: GloVe.6B.50d, factor3: LSTM, factor4: 0.3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the prediction on the test data\n",
    "# 1 - disaster tweet , 0 - non-disaster tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2 = model2.predict_classes(X_test)\n",
    "predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv\n",
    "submission_df = pd.DataFrame({'id':test_tweets['id'],'target':np.squeeze(predict2)})\n",
    "submission_df.to_csv('submission_rnn_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the accuracy and kaggle score for this model \n",
    "results_tbl = results_tbl.append({'Model_name':'RNN #2', \n",
    "                                   'vocabulary size (factor1)':'400K',\n",
    "                                   'pre-trained vector (factor2)':'GloVe.6B.50d',\n",
    "                                   'RNN structure (factor3)':'LSTM layer based',\n",
    "                                   'hyperparameter recurrent_dropout (factor4)': '0.3',\n",
    "                                   'Processing Time':(end-start),\n",
    "                                   'Training Set Accuracy':best_model_train_accuracy,\n",
    "                                   'Validation Set Accuracy':best_model_val_accuracy,\n",
    "                                   'train f1':best_model_train_f1,\n",
    "                                   'validation f1':best_model_val_f1,\n",
    "                                   'Test Set F1-score (Kaggle score)': '0.78026'\n",
    "                                   },ignore_index=True)\n",
    "results_tbl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RNN 3\n",
    "# vocabulary size (factor 1): 400K\n",
    "# pre-trained vector (factor 2): GloVe.6B.200d\n",
    "# rnn structure (factor 3): GRU layer based structure\n",
    "# recurrent dropout (factor 4): 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.models.Sequential([\n",
    "    keras.layers.Embedding(len(word2index)+1,\n",
    "                           50,\n",
    "                           weights=[embedding_matrix],\n",
    "                           input_length=maxlen,\n",
    "                           trainable=True),\n",
    "    keras.layers.GRU(units=128 , return_sequences = True , recurrent_dropout = 0.1, dropout = 0.1),\n",
    "    keras.layers.GRU(units=64 , recurrent_dropout = 0.1 , dropout = 0.1),\n",
    "    keras.layers.Dense(22, activation='tanh'),\n",
    "    keras.layers.Dense(4, activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(learning_rate=1e-5)\n",
    "model3.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy', f1_m],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model; obtain the model fit time\n",
    "start=datetime.now()\n",
    "history3 = model3.fit(X_train,Y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=40,\n",
    "                    validation_split=0.3\n",
    ")\n",
    "end=datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Train Accuracy: ')\n",
    "best_model_train_accuracy = np.round(history3.history['accuracy'][np.argmin(history3.history['loss'])],4)\n",
    "best_model_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Validation Accuracy: ')\n",
    "best_model_val_accuracy = np.round(history3.history['val_accuracy'][np.argmin(history3.history['val_loss'])],4)\n",
    "best_model_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = max(np.round(history3.history['f1_m'],4))\n",
    "print ('Best Train f1: {}'.format(best_model_train_f1))\n",
    "\n",
    "best_model_val_f1 = max(np.round(history3.history['val_f1_m'],4))\n",
    "print ('Best val f1: {}'.format(best_model_val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "pd.DataFrame(history3.history).plot(figsize=(10, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.title('Learning curve - factor1: 400K, factor2: GloVe.6B.50d, factor3: GRU, factor4: 0.1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the prediction on the test data\n",
    "# 1 - disaster tweet , 0 - non-disaster tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict3 = model3.predict_classes(X_test)\n",
    "predict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv\n",
    "submission_df = pd.DataFrame({'id':test_tweets['id'],'target':np.squeeze(predict3)})\n",
    "submission_df.to_csv('submission_rnn_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the accuracy and kaggle score for this model \n",
    "results_tbl = results_tbl.append({'Model_name':'RNN #3', \n",
    "                                   'vocabulary size (factor1)':'400K',\n",
    "                                   'pre-trained vector (factor2)':'GloVe.6B.50d',\n",
    "                                   'RNN structure (factor3)':'GRU layer based',\n",
    "                                   'hyperparameter recurrent_dropout (factor4)': '0.1',\n",
    "                                   'Processing Time':(end-start),\n",
    "                                   'Training Set Accuracy':best_model_train_accuracy,\n",
    "                                   'Validation Set Accuracy':best_model_val_accuracy,\n",
    "                                   'train f1':best_model_train_f1,\n",
    "                                   'validation f1':best_model_val_f1,\n",
    "                                   'Test Set F1-score (Kaggle score)': '0.78302'\n",
    "                                   },ignore_index=True)\n",
    "results_tbl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RNN 4\n",
    "# vocabulary size (factor 1): 400K\n",
    "# pre-trained vector (factor 2): GloVe.6B.200d\n",
    "# rnn structure (factor 3): GRU based structure\n",
    "# recurrent dropout (factor 4): 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.models.Sequential([\n",
    "    keras.layers.Embedding(len(word2index)+1, 50, weights=[embedding_matrix],\n",
    "                           input_length=maxlen,\n",
    "                           trainable=True),\n",
    "    keras.layers.GRU(units=128 , return_sequences = True),\n",
    "    keras.layers.GRU(units=64 , recurrent_dropout = 0.1),\n",
    "    keras.layers.Dense(22, activation='tanh'),\n",
    "    keras.layers.Dense(4, activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(learning_rate=1e-5)\n",
    "model4.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy', f1_m],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model; obtain the model fit time\n",
    "start=datetime.now()\n",
    "history4 = model4.fit(X_train,Y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=25,\n",
    "                    validation_split=0.3\n",
    ")\n",
    "end=datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Train Accuracy: ')\n",
    "best_model_train_accuracy = np.round(history4.history['accuracy'][np.argmin(history4.history['loss'])],4)\n",
    "best_model_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Validation Accuracy: ')\n",
    "best_model_val_accuracy = np.round(history4.history['val_accuracy'][np.argmin(history4.history['val_loss'])],4)\n",
    "best_model_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = max(np.round(history4.history['f1_m'],4))\n",
    "print ('Best Train f1: {}'.format(best_model_train_f1))\n",
    "\n",
    "best_model_val_f1 = max(np.round(history4.history['val_f1_m'],4))\n",
    "print ('Best val f1: {}'.format(best_model_val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "pd.DataFrame(history4.history).plot(figsize=(10, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.title('Learning curve - factor1: 400K, factor2: GloVe.6B.50d, factor3: GRU, factor4: 0.3')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the prediction on the test data\n",
    "# 1 - disaster tweet , 0 - non-disaster tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict4 = model4.predict_classes(X_test)\n",
    "predict4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv\n",
    "submission_df = pd.DataFrame({'id':test_tweets['id'],'target':np.squeeze(predict4)})\n",
    "submission_df.to_csv('submission_rnn_4.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Store the accuracy and kaggle score for this model \n",
    "results_tbl = results_tbl.append({'Model_name':'RNN #4', \n",
    "                                   'vocabulary size (factor1)':'400K',\n",
    "                                   'pre-trained vector (factor2)':'GloVe.6B.50d',\n",
    "                                   'RNN structure (factor3)':'GRU layer based',\n",
    "                                   'hyperparameter recurrent_dropout (factor4)': '0.3',\n",
    "                                   'Processing Time':(end-start),\n",
    "                                   'Training Set Accuracy':best_model_train_accuracy,\n",
    "                                   'Validation Set Accuracy':best_model_val_accuracy,\n",
    "                                   'train f1':best_model_train_f1,\n",
    "                                   'validation f1':best_model_val_f1,\n",
    "                                   'Test Set F1-score (Kaggle score)': '0.77873'\n",
    "                                   },ignore_index=True)\n",
    "results_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RNN 5\n",
    "# vocabulary size (factor 1): 400K\n",
    "# pre-trained vector (factor 2): GloVe.6B.200d\n",
    "# rnn structure (factor 3): LSTM layer based structure\n",
    "# recurrent dropout (factor 4): 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = keras.models.Sequential([\n",
    "    keras.layers.Embedding(len(word2index)+1,200,weights=[embedding_matrix],input_length=maxlen,trainable=False),\n",
    "    keras.layers.LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.1 , dropout = 0.1),\n",
    "    keras.layers.LSTM(units=64 , recurrent_dropout = 0.1 , dropout = 0.1),\n",
    "    keras.layers.Dense(32, activation='tanh'),\n",
    "    keras.layers.Dense(1,activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(learning_rate=1e-5)\n",
    "model5.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy', f1_m],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model; obtain the model fit time\n",
    "start=datetime.now()\n",
    "history5 = model5.fit(X_train,Y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=40,\n",
    "                    validation_split=0.1\n",
    ")\n",
    "end=datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Train Accuracy: ')\n",
    "best_model_train_accuracy = np.round(history5.history['accuracy'][np.argmin(history5.history['loss'])],4)\n",
    "best_model_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Validation Accuracy: ')\n",
    "best_model_val_accuracy = np.round(history5.history['val_accuracy'][np.argmin(history5.history['val_loss'])],4)\n",
    "best_model_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = max(np.round(history5.history['f1_m'],4))\n",
    "print ('Best Train f1: {}'.format(best_model_train_f1))\n",
    "\n",
    "best_model_val_f1 = max(np.round(history5.history['val_f1_m'],4))\n",
    "print ('Best val f1: {}'.format(best_model_val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the learning curve\n",
    "pd.DataFrame(history5.history).plot(figsize=(10, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.title('Learning curve - factor1: 400K, factor2: GloVe.6B.200d, factor3: LSTM, factor4: 0.1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_text)\n",
    "padded_seq = keras.preprocessing.sequence.pad_sequences(test_sequences,maxlen)\n",
    "X_test = padded_seq\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict5 = model5.predict_classes(X_test)\n",
    "predict5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv\n",
    "submission_df = pd.DataFrame({'id':test_tweets['id'],'target':np.squeeze(predict5)})\n",
    "submission_df.to_csv('submission_rnn_5.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the accuracy and kaggle score for this model \n",
    "results_tbl = results_tbl.append({'Model_name':'RNN #5', \n",
    "                                   'vocabulary size (factor1)':'400K',\n",
    "                                   'pre-trained vector (factor2)':'GloVe.6B.200d',\n",
    "                                   'RNN structure (factor3)':'LSTM layer based',\n",
    "                                   'hyperparameter recurrent_dropout (factor4)': '0.1',\n",
    "                                   'Processing Time':(end-start),\n",
    "                                   'Training Set Accuracy':best_model_train_accuracy,\n",
    "                                   'Validation Set Accuracy':best_model_val_accuracy,\n",
    "                                   'train f1':best_model_train_f1,\n",
    "                                   'validation f1':best_model_val_f1,\n",
    "                                   'Test Set F1-score (Kaggle score)': '0.79313'\n",
    "                                   },ignore_index=True)\n",
    "results_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RNN 6\n",
    "# vocabulary size (factor 1): 400K\n",
    "# pre-trained vector (factor 2): GloVe.6B.200d\n",
    "# rnn structure (factor 3): LSTM layer based structure\n",
    "# recurrent dropout (factor 4): 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = keras.models.Sequential([\n",
    "    keras.layers.Embedding(len(word2index)+1,200,weights=[embedding_matrix],input_length=maxlen,trainable=False),\n",
    "    keras.layers.LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.3 , dropout = 0.3),\n",
    "    keras.layers.LSTM(units=64 , recurrent_dropout = 0.3 , dropout = 0.3),\n",
    "    keras.layers.Dense(32, activation='tanh'),\n",
    "    keras.layers.Dense(1,activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(learning_rate=1e-5)\n",
    "model6.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy', f1_m],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model; obtain the model fit time\n",
    "start=datetime.now()\n",
    "history6 = model6.fit(X_train,Y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=40,\n",
    "                    validation_split=0.3\n",
    ")\n",
    "end=datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Train Accuracy: ')\n",
    "best_model_train_accuracy = np.round(history6.history['accuracy'][np.argmin(history6.history['loss'])],4)\n",
    "best_model_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Validation Accuracy: ')\n",
    "best_model_val_accuracy = np.round(history6.history['val_accuracy'][np.argmin(history6.history['val_loss'])],4)\n",
    "best_model_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = max(np.round(history6.history['f1_m'],4))\n",
    "print ('Best Train f1: {}'.format(best_model_train_f1))\n",
    "\n",
    "best_model_val_f1 = max(np.round(history6.history['val_f1_m'],4))\n",
    "print ('Best val f1: {}'.format(best_model_val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the learning curve\n",
    "pd.DataFrame(history6.history).plot(figsize=(10, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.title('Learning curve - factor1: 400K, factor2: GloVe.6B.200d, factor3: LSTM, factor4: 0.3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the prediction on the test data\n",
    "# 1 - disaster tweet , 0 - non-disaster tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict6 = model6.predict_classes(X_test)\n",
    "predict6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv\n",
    "submission_df = pd.DataFrame({'id':test_tweets['id'],'target':np.squeeze(predict6)})\n",
    "submission_df.to_csv('submission_rnn_6.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the accuracy and kaggle score for this model \n",
    "results_tbl = results_tbl.append({'Model_name':'RNN #6', \n",
    "                                   'vocabulary size (factor1)':'400K',\n",
    "                                   'pre-trained vector (factor2)':'GloVe.6B.200d',\n",
    "                                   'RNN structure (factor3)':'LSTM layer based',\n",
    "                                   'hyperparameter recurrent_dropout (factor4)': '0.3',\n",
    "                                   'Processing Time':(end-start),\n",
    "                                   'Training Set Accuracy':best_model_train_accuracy,\n",
    "                                   'Validation Set Accuracy':best_model_val_accuracy,\n",
    "                                   'train f1':best_model_train_f1,\n",
    "                                   'validation f1':best_model_val_f1,\n",
    "                                   'Test Set F1-score (Kaggle score)': '0.78639'\n",
    "                                   },ignore_index=True)\n",
    "results_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RNN 7\n",
    "# vocabulary size (factor 1): 400K\n",
    "# pre-trained vector (factor 2): GloVe.6B.200d\n",
    "# rnn structure (factor 3): GRU layer based structure\n",
    "# recurrent dropout (factor 4): 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model7 = keras.models.Sequential([\n",
    "    keras.layers.Embedding(len(word2index)+1,200,weights=[embedding_matrix],input_length=maxlen,trainable=False),\n",
    "    keras.layers.GRU(units=128 , return_sequences = True , recurrent_dropout = 0.1 , dropout = 0.1),\n",
    "    keras.layers.GRU(units=64 , recurrent_dropout = 0.1 , dropout = 0.1),\n",
    "    keras.layers.Dense(32, activation='tanh'),\n",
    "    keras.layers.Dense(1,activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(learning_rate=1e-5)\n",
    "model7.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy', f1_m],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model; obtain the model fit time\n",
    "start=datetime.now()\n",
    "history7 = model7.fit(X_train,Y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=40,\n",
    "                    validation_split=0.3\n",
    ")\n",
    "end=datetime.now()\n",
    "print(end-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print ('Best Train Accuracy: ')\n",
    "best_model_train_accuracy = np.round(history7.history['accuracy'][np.argmin(history7.history['loss'])],4)\n",
    "best_model_train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Validation Accuracy: ')\n",
    "best_model_val_accuracy = np.round(history7.history['val_accuracy'][np.argmin(history7.history['val_loss'])],4)\n",
    "best_model_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = max(np.round(history7.history['f1_m'],4))\n",
    "print ('Best Train f1: {}'.format(best_model_train_f1))\n",
    "\n",
    "best_model_val_f1 = max(np.round(history7.history['val_f1_m'],4))\n",
    "print ('Best val f1: {}'.format(best_model_val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "pd.DataFrame(history7.history).plot(figsize=(10, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.title('Learning curve - factor1: 400K, factor2: GloVe.6B.200d, factor3: GRU, factor4: 0.1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the prediction on the test data\n",
    "\n",
    "# 1 - disaster tweet , 0 - non-disaster tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict7 = model7.predict_classes(X_test)\n",
    "predict7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv\n",
    "submission_df = pd.DataFrame({'id':test_tweets['id'],'target':np.squeeze(predict7)})\n",
    "submission_df.to_csv('submission_rnn_7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the accuracy and kaggle score for this model \n",
    "results_tbl = results_tbl.append({'Model_name':'RNN #7', \n",
    "                                   'vocabulary size (factor1)':'400K',\n",
    "                                   'pre-trained vector (factor2)':'GloVe.6B.200d',\n",
    "                                   'RNN structure (factor3)':'GRU layer based',\n",
    "                                   'hyperparameter recurrent_dropout (factor4)': '0.1',\n",
    "                                   'Processing Time':(end-start),\n",
    "                                   'Training Set Accuracy':best_model_train_accuracy,\n",
    "                                   'Validation Set Accuracy':best_model_val_accuracy,\n",
    "                                   'train f1':best_model_train_f1,\n",
    "                                   'validation f1':best_model_val_f1,\n",
    "                                   'Test Set F1-score (Kaggle score)': '0.79068'\n",
    "                                   },ignore_index=True)\n",
    "results_tbl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RNN 8\n",
    "# vocabulary size (factor 1): 400K\n",
    "# pre-trained vector (factor 2): GloVe.6B.200d\n",
    "# rnn structure (factor 3): GRU based structure\n",
    "# recurrent dropout (factor 4): 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = keras.models.Sequential([\n",
    "    keras.layers.Embedding(len(word2index)+1,200,weights=[embedding_matrix],input_length=maxlen,trainable=False),\n",
    "    keras.layers.GRU(units=128 , return_sequences = True , recurrent_dropout = 0.3 , dropout = 0.3),\n",
    "    keras.layers.GRU(units=64 , recurrent_dropout = 0.3 , dropout = 0.3),\n",
    "    keras.layers.Dense(32, activation='tanh'),\n",
    "    keras.layers.Dense(1,activation='tanh')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(learning_rate=1e-5)\n",
    "model8.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy', f1_m],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the model; obtain the model fit time\n",
    "start=datetime.now()\n",
    "history8 = model8.fit(X_train,Y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=40,\n",
    "                    validation_split=0.3\n",
    ")\n",
    "end=datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Train Accuracy: ')\n",
    "best_model_train_accuracy = np.round(history8.history['accuracy'][np.argmin(history8.history['loss'])],4)\n",
    "best_model_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Best Validation Accuracy: ')\n",
    "best_model_val_accuracy = np.round(history8.history['val_accuracy'][np.argmin(history8.history['val_loss'])],4)\n",
    "best_model_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_f1 = max(np.round(history8.history['f1_m'],4))\n",
    "print ('Best Train f1: {}'.format(best_model_train_f1))\n",
    "\n",
    "best_model_val_f1 = max(np.round(history8.history['val_f1_m'],4))\n",
    "print ('Best val f1: {}'.format(best_model_val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "pd.DataFrame(history8.history).plot(figsize=(10, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.title('Learning curve - factor1: 400K, factor2: GloVe.6B.200d, factor3: GRU, factor4: 0.3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the prediction on the test data\n",
    "# 1 - disaster tweet , 0 - non-disaster tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict8 = model8.predict_classes(X_test)\n",
    "predict8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv\n",
    "submission_df = pd.DataFrame({'id':test_tweets['id'],'target':np.squeeze(predict8)})\n",
    "submission_df.to_csv('submission_rnn_8.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the accuracy and kaggle score for this model \n",
    "results_tbl = results_tbl.append({'Model_name':'RNN #8', \n",
    "                                   'vocabulary size (factor1)':'400K',\n",
    "                                   'pre-trained vector (factor2)':'GloVe.6B.200d',\n",
    "                                   'RNN structure (factor3)':'GRU layer based',\n",
    "                                   'hyperparameter recurrent_dropout (factor4)': '0.3',\n",
    "                                   'Processing Time':(end-start),\n",
    "                                   'Training Set Accuracy':best_model_train_accuracy,\n",
    "                                   'Validation Set Accuracy':best_model_val_accuracy,\n",
    "                                   'train f1':best_model_train_f1,\n",
    "                                   'validation f1':best_model_val_f1,\n",
    "                                   'Test Set F1-score (Kaggle score)': '0.78608'\n",
    "                                   },ignore_index=True)\n",
    "results_tbl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
